{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from mdng_client import OTReader\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "reader = OTReader(tz='America/New_York', env='Prod') \n",
    "\n",
    "\n",
    "start = '2014-01-01 00:00:00'\n",
    "end = '2021-10-28 16:00:00'\n",
    "\n",
    "symbols = ['BBGTKR::BLOOMBERG::AUDJPY CURNCY']\n",
    "tick_type = 'TRD'\n",
    "\n",
    "\n",
    "a = reader.get_resampled_ticks(symbols=symbols, start=start,\n",
    "                            end=end, tick_type=tick_type,\n",
    "                            bucket_size='2',\n",
    "                            bucket_units='HOURS',\n",
    "                            fields=['HIGH','LOW','OPEN','CLOSE'])\n",
    "\n",
    "\n",
    "a=pd.DataFrame(a)\n",
    "print(a)\n",
    "\n",
    "tick_type = 'QTE'\n",
    "b = reader.get_resampled_ticks(symbols=symbols, start=start,\n",
    "                            end=end, tick_type=tick_type,\n",
    "                            bucket_size='2',\n",
    "                            bucket_units='HOURS',\n",
    "                            fields=['BID_PRICE','ASK_PRICE'])\n",
    "\n",
    "\n",
    "print(b)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_type = 'TRD'\n",
    "d = reader.get_resampled_ticks(symbols=symbols, start=start,\n",
    "                            end=end, tick_type=tick_type,\n",
    "                            bucket_size='30',\n",
    "                            bucket_units='MINUTES',\n",
    "                            fields=['HIGH','LOW','OPEN','CLOSE','NUM_TICKS'])\n",
    "\n",
    "\n",
    "d=pd.DataFrame(d)\n",
    "d[\"tickqty\"] = d['NUM_TICKS'].rolling(4).sum()\n",
    "d.reset_index(level=0, inplace=True)   \n",
    "\n",
    "#d = datetime.today().strftime('%Y-%m-%d')\n",
    "#d.reset_index(level=0, inplace=True)\n",
    "d[\"date\"]= pd.to_datetime(d[\"TIME\"]) \n",
    "#d[\"date\"]=float(d[\"date\"])\n",
    "\n",
    "d[\"date1\"]=d[\"date\"].dt.day_name()\n",
    "d=d.loc[d['date1'].isin(['Monday','Tuesday','Wednesday','Thursday','Friday'])]\n",
    "d[\"tickqty\"] = (d['NUM_TICKS'].rolling(4).sum())*20\n",
    "\n",
    "\n",
    "d=d[[\"date\",\"tickqty\"]]\n",
    "d.columns=['TIME','tickqty']\n",
    "print(d)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d.to_clipboard()\n",
    "#from datetime import datetime, timedelta\n",
    "#d = d[(d.date.dayofweek < 5)]\n",
    "#print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=pd.merge(a, b,  how='left', left_on=['TIME'], right_on = ['TIME']).fillna(method='bfill')\n",
    "print(len(c))\n",
    "c=pd.merge(c, d,  how='left', left_on=['TIME'], right_on = ['TIME']).fillna(method='bfill')\n",
    "print(len(c))\n",
    "\n",
    "\n",
    "\n",
    "print(c.columns)\n",
    "#c=c[[\"HIGH\",\"LOW\",\"OPEN\",\"CLOSE\",\"BID_PRICE\",\"ASK_PRICE\",\"NUM_TICKS\"]]\n",
    "c=c[[\"TIME\", \"HIGH\",\"LOW\",\"OPEN\",\"CLOSE\",\"BID_PRICE\",\"ASK_PRICE\",\"tickqty\"]]\n",
    "c[\"spread\"]=c[\"ASK_PRICE\"]  -c[\"BID_PRICE\"]  \n",
    "c.reset_index(level=0, inplace=True)\n",
    "c[\"date\"]=c[\"TIME\"]\n",
    "c[\"askopen\"]=c[\"OPEN\"]\n",
    "c[\"askclose\"]=c[\"CLOSE\"]\n",
    "c[\"askhigh\"]=c[\"HIGH\"]\n",
    "c[\"asklow\"]=c[\"LOW\"]\n",
    "\n",
    "c[\"bidopen\"]=c[\"askopen\"]+c[\"spread\"]\n",
    "c[\"bidclose\"]=c[\"askclose\"]+c[\"spread\"]\n",
    "c[\"bidhigh\"]=c[\"askhigh\"]+c[\"spread\"]\n",
    "c[\"bidlow\"]=c[\"asklow\"]+c[\"spread\"]\n",
    "\n",
    "#c[\"tickqty\"]=c[\"NUM_TICKS\"]*20\n",
    "#c.reset_index(level=0, inplace=True)\n",
    "print(c)\n",
    "#c[\"date\"]=c[\"TIME\"]\n",
    "\n",
    "c=c[[\"date\",\"askopen\",\"askclose\",\"askhigh\", \"asklow\",\"bidopen\",\"bidclose\",\"bidhigh\",\"bidlow\",\"tickqty\"]]\n",
    "\n",
    "#c=c[[\"askopen\",\"askclose\",\"askhigh\", \"asklow\",\"bidopen\",\"bidclose\",\"bidhigh\",\"bidlow\",\"tickqty\"]]\n",
    "c.to_clipboard()\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.path.realpath(r'K:\\2020_2431\\q\\fx_g10_st\\fx_g10_st')\n",
    "#K:\\2020_2431\\q\\fx_g10_st\\input_data\n",
    "\n",
    "#tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDUSD.csv')\n",
    "\n",
    "\n",
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\EURUSD.csv')\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(1).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\EURUSD.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDUSD.csv')\n",
    "print(tab.head(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDJPY.csv')\n",
    "print(tab.head(5))\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(3).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDJPY.csv', index = False, header=True)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\GBPUSD.csv')\n",
    "print(tab.head(5))\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(1).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\GBPUSD.csv', index = False, header=True)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\NZDUSD.csv')\n",
    "print(tab.head(5))\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(1).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\NZDUSD.csv', index = False, header=True)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\USDJPY.csv')\n",
    "print(tab.head(5))\n",
    "\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(1).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\USDJPY.csv', index = False, header=True)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\USDCAD.csv')\n",
    "\n",
    "print(tab.head(5))\n",
    "\n",
    "aaaaa\n",
    "tab['date'] = pd.to_datetime(tab['date'], format='%d/%m/%Y %H:%M') \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.drop(tab.tail(1).index,inplace=True)\n",
    "print(tab)\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\USDCAD.csv', index = False, header=True)\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tb = pd.read_csv('AUDUSD.csv')\n",
    "\n",
    "#tab[\"date\"]= pd.to_datetime(tab[\"date\"],format='%Y-%m-%d, %H:%M:%S', errors='coerce')\n",
    "#tab[\"date\"]= pd.to_datetime(tab[\"date\"],format='%Y-%m-%d, %H:%M', errors='coerce')\n",
    "#tab['date'] = tab['date'].astype('datetime64[ns]')\n",
    "#tab[\"date\"]=datetime.strptime(tab[\"date\"], '%Y-%m-%d %H:%M')\n",
    "\n",
    "#tab['date'] = tab['date'].datetime.strptime()\n",
    "#ir.index =[dt.datetime.strptime(date, '%Y-%m-%d %H:%M:%S') for date in ir.date]\n",
    "#tab[\"date\"]=datetime.strptime(tab[\"date\"], '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vix.to_csv (r'K:\\2020_2431\\q\\sandbox_gm\\vix_tmp.csv', index = True, header=True)\n",
    "df['Dates'] = pd.to_datetime(df['Dates'], format='%y%m%d') \n",
    "\n",
    "df['Date'] = df['Date'].astype('datetime64[ns]')\n",
    "\n",
    "dtype = pd.SparseDtype(np.dtype('datetime64[ns]'))\n",
    "series = pd.Series(df.date, dtype=dtype)\n",
    "df['date']=np.array(series)\n",
    "#tab[\"date\"]=(tab[\"date\"].str())\n",
    "#tab[\"date\"]= pd.to_datetime(tab[\"date\"], errors='coerce')\n",
    "#tab['date'] = pd.to_datetime(tab['date'], format='%Y-%m-%d %H:%M:%S') \n",
    "#, format='%Y-%m-%d %H:%M:%S') \n",
    "#tab[\"date\"]=tab[\"date\"].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#tab[\"date\"]=datetime.strptime(tab[\"date\"], '%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDUSD.csv')\n",
    "print(tab)\n",
    "tab['date'] = pd.to_datetime(tab['date'], format=\"%Y-%m-%d %H:%M:%S\") \n",
    "tab[\"date\"] = tab[\"date\"].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\AUDUSD.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv(r'K:\\2020_2431\\q\\fx_g10_st\\input_data\\NZDUSD.csv')\n",
    "tab[\"date\"]=dt.strptime(tab[\"date\"], '%Y-%m-%d %H:%M:%S')\n",
    "tab.to_csv (r'K:\\2020_2431\\q\\sandbox_gm\\NZDUSD.csv', index = False, header=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#date\tbidopen\tbidclose\tbidhigh\tbidlow\taskopen\taskclose\taskhigh\tasklow\ttickqty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#IMPORT PACKAGES \n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import pandas as pd\n",
    "from alphasuite.providers import MarketDataProvider\n",
    "from alphasuite.market import market_data_upload\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from mdng_client import OTReader\n",
    "#####CHANGE UAT TO PROD\n",
    "reader = OTReader(tz='America/New_York', env='PROD')\n",
    "\n",
    "# the timezone for start/end and returned timestamps\n",
    "\n",
    "from mdng_client.utils import format_to_melted_df\n",
    "from mdng_client import OTReader\n",
    "import onetick.query as otq\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "reader = OTReader(tz='America/New_York', env='PROD')\n",
    "reader = OTReader(tz='America/New_York', env='PROD')\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def from_name_source_as_of_time(names, source, as_of_time, is_eod):\n",
    "    # need some logic to determine if they are querying EOD or intradaY\n",
    "    if is_eod:\n",
    "        tick_type = 'DAY' # change as needed for object\n",
    "    else:\n",
    "        tick_type = 'TRD'\n",
    "        \n",
    "    symbols = ['BBGTKR::BLOOMBERG::' + name.upper() for name in names]\n",
    "    graph = otq.Graph(\n",
    "            otq.Chainlet(\n",
    "                otq.Passthrough().tick_type(tick_type),\n",
    "                otq.WhereClause(discard_on_match=False, where=\"SOURCE='{}'\".format(source.upper()))\n",
    "            )\n",
    "    )\n",
    "    # interval is [start, end)\n",
    "    start = as_of_time - timedelta(days=10000)\n",
    "    end = as_of_time\n",
    "\n",
    "    result = reader.run_generic_query(\n",
    "        graph_or_otq=graph,\n",
    "        symbols=symbols,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        symbol_date=as_of_time,\n",
    "    )\n",
    "    return format_to_melted_df(symbols=symbols, result=result)\n",
    "########\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as_of_date = datetime.today()\n",
    "\n",
    "symbols = ['BRL CURNCY', 'CLP CURNCY','CZK CURNCY','IDR CURNCY','ILS CURNCY','INR CURNCY','KRW CURNCY','MXN CURNCY',\n",
    "           'PEN CURNCY','PLN CURNCY','RUB CURNCY','HUF CURNCY','ZAR CURNCY','THB CURNCY','PHP CURNCY','TRY CURNCY',\n",
    "           'CNH CURNCY','COP CURNCY','TWD CURNCY','MYR CURNCY']           \n",
    "#'EUR CURNCY','GBP CURNCY','JPY CURNCY' ,'NZD CURNCY','AUD CURNCY', 'CHF CURNCY','NOK CURNCY','CAD CURNCY']        \n",
    "     \n",
    "test00001 = from_name_source_as_of_time(symbols, 'BGN', as_of_date, True)\n",
    "test00001.drop_duplicates()\n",
    "test00001 = test00001.reset_index()  \n",
    "test00001[\"TIME\"]=test00001[\"TIME\"].dt.strftime(\"%Y-%m-%d\")\n",
    "test00001=test00001[['TIME','PX_LAST','TICKER']]\n",
    "#test00001.drop_duplicates()\n",
    "#test00001['TIME']=str(test00001['TIME'])               \n",
    "#test00001['year'] = pd.DatetimeIndex(test00001['TIME']).year\n",
    "#test00001['month'] = str(pd.DatetimeIndex(test00001['TIME']).month)\n",
    "#test00001['day'] = str(pd.DatetimeIndex(test00001['TIME']).day)\n",
    "#df['Dates'] = pd.to_datetime(df['Dates'], format='%y%m%d')\n",
    "\n",
    "test00002=pd.pivot_table(test00001,index=[\"TIME\"],values=[\"PX_LAST\"], columns=[\"TICKER\"],aggfunc=[np.sum])\n",
    "test00002=test00002.fillna(method='bfill')\n",
    "test00002=test00002.fillna(method='bfill')\n",
    "#remove amount\n",
    "test00002.columns = test00002.columns.droplevel(0) \n",
    "test00002.columns = test00002.columns.droplevel(0) \n",
    "\n",
    "test00002 = test00002.reset_index()  \n",
    "test00002=test00002.set_index('TIME')\n",
    "#test00002['date'] = test00002['date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "\n",
    "\n",
    "test00002=test00002.replace(to_replace=0, method='ffill')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test00002.to_csv (r'K:\\2020_2431\\q\\sandbox_gm\\fx_tmp.csv', index = True, header=True)\n",
    "print(\"Complete!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KuQfyFeA8h1YvdqUT2sjmVBa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: histdata in c:\\anaconda_2020.11\\lib\\site-packages (1.0)\n",
      "Requirement already satisfied: requests in c:\\anaconda_2020.11\\lib\\site-packages (from histdata) (2.24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda_2020.11\\lib\\site-packages (from histdata) (4.9.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda_2020.11\\lib\\site-packages (from requests->histdata) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda_2020.11\\lib\\site-packages (from requests->histdata) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\anaconda_2020.11\\lib\\site-packages (from requests->histdata) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda_2020.11\\lib\\site-packages (from requests->histdata) (2.10)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\anaconda_2020.11\\lib\\site-packages (from beautifulsoup4->histdata) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install histdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import histdata\n",
    "\n",
    "from histdata import download_hist_data as dl\n",
    "from histdata.api import Platform as P, TimeFrame as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.histdata.com/download-free-forex-historical-data/?/ascii/tick-data-quotes/eurusd/2019/6\n",
      "{'tk': 'bf6856b7e2ab03811c92d3253e89a88d', 'date': '2019', 'datemonth': '201906', 'platform': 'ASCII', 'timeframe': 'T', 'fxpair': 'EURUSD'}\n",
      "Wrote to .\\DAT_ASCII_EURUSD_T_201906.zip\n",
      ".\\DAT_ASCII_EURUSD_T_201906.zip\n"
     ]
    }
   ],
   "source": [
    "a= dl(year='2019', month='6', pair='eurusd', platform=P.GENERIC_ASCII, time_frame=TF.TICK_DATA)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-1fc0e73de3e5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-1fc0e73de3e5>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    python download_all_fx_data.py\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "python download_all_fx_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/philipperemy/FX-1-Minute-Data\n",
    "    https://github.com/fxcm/MarketData\n",
    "        https://towardsdatascience.com/how-and-why-i-got-75gb-of-free-foreign-exchange-tick-data-9ca78f5fa26c\n",
    "            https://www.histdata.com/download-free-forex-historical-data/?/ascii/tick-data-quotes/eurusd/2019/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpleaudio\n",
      "  Downloading simpleaudio-1.0.4-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Installing collected packages: simpleaudio\n",
      "Successfully installed simpleaudio-1.0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/f8/f0/baa21582912d8e9734635ec5b74d03a56730997da371205bab353ec954c7/simpleaudio-1.0.4-cp38-cp38-win_amd64.whl\n"
     ]
    }
   ],
   "source": [
    "!pip install simpleaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    # libraries you will need\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "import requests\n",
    "import fxcmpy\n",
    "from fxcmpy import fxcmpy_tick_data_reader as tdr\n",
    "import os\n",
    "import gzip\n",
    "from io import StringIO\n",
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cabcffbac704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{directory}{symbol}_{year}_w{week}.csv.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                     \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Construct the years, weeks and symbol lists required for the scraper.\n",
    "years = [2017, 2018]\n",
    "weeks = list(range(53))\n",
    "symbols = []\n",
    "for pair in tdr.get_available_symbols():\n",
    "    if pair not in symbols:\n",
    "        symbols.append(pair)\n",
    "\n",
    "# Scrape time\n",
    "\n",
    "\n",
    "directory = r\"K:/2020_2431/FX valuation model 2020/g10/voting/\"\n",
    "\n",
    "for symbol in symbols:    \n",
    "    for year in years:\n",
    "        for week in weeks:\n",
    "            url = f\"https://tickdata.fxcorporate.com/{symbol}/{year}/{week}.csv.gz\"\n",
    "            r = requests.get(url, stream=True)\n",
    "            with open(f\"{directory}{symbol}_{year}_w{week}.csv.gz\", 'wb') as file:\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDCAD files downloaded = 159 \n",
      "AUDCHF files downloaded = 125 \n",
      "AUDJPY files downloaded = 53 \n",
      "AUDNZD files downloaded = 53 \n",
      "CADCHF files downloaded = 53 \n",
      "EURAUD files downloaded = 53 \n",
      "EURCHF files downloaded = 53 \n",
      "EURGBP files downloaded = 53 \n",
      "EURJPY files downloaded = 53 \n",
      "EURUSD files downloaded = 53 \n",
      "GBPCHF files downloaded = 53 \n",
      "GBPJPY files downloaded = 53 \n",
      "GBPNZD files downloaded = 53 \n",
      "GBPUSD files downloaded = 53 \n",
      "NZDCAD files downloaded = 53 \n",
      "NZDCHF files downloaded = 53 \n",
      "NZDJPY files downloaded = 53 \n",
      "NZDUSD files downloaded = 53 \n",
      "USDCAD files downloaded = 53 \n",
      "USDCHF files downloaded = 53 \n",
      "USDJPY files downloaded = 53 \n",
      "\n",
      "Total files downloaded = 1291\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construct the years, weeks and symbol lists required for the scraper.\n",
    "years = [2020]\n",
    "weeks = list(range(53))\n",
    "symbols = []\n",
    "for pair in tdr.get_available_symbols():\n",
    "    if pair not in symbols:\n",
    "        symbols.append(pair)\n",
    "\n",
    "# Scrape time\n",
    "directory = r\"K:/2020_2431/FX valuation model 2020/g10/voting/\"\n",
    "\n",
    "for symbol in symbols:    \n",
    "    for year in years:\n",
    "        for week in weeks:\n",
    "            url = f\"https://tickdata.fxcorporate.com/{symbol}/{year}/{week}.csv.gz\"\n",
    "            r = requests.get(url, stream=True)\n",
    "            with open(f\"{directory}{symbol}_{year}_w{week}.csv.gz\", 'wb') as file:\n",
    "                for chunk in r.iter_content(chunk_size=1024):\n",
    "                    file.write(chunk)\n",
    "\n",
    "# Check all the files for each currency pair was downloaded (should be 104 for each)\n",
    "total = 0\n",
    "for symbol in symbols:\n",
    "    count = 0\n",
    "    for file in os.listdir(directory):\n",
    "        if file[:6] == symbol:\n",
    "            count+=1\n",
    "    total += count\n",
    "    print(f\"{symbol} files downloaded = {count} \")\n",
    "print(f\"\\nTotal files downloaded = {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL script\n",
    "directory = r\"K:/2020_2431/FX valuation model 2020/g10/voting/\"\n",
    "\n",
    "#directory = \"/location_of/scraped/files/\"\n",
    "hdf5_file = '/Volumes/external_hd/FxTickData.h5'\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith('.gz'):\n",
    "        print(f\"\\nExtracting: {file}\")\n",
    "        \n",
    "        # extract gzip file and assign to Dataframe\n",
    "        codec = 'utf-16'\n",
    "        f = gzip.GzipFile(f'{directory}{file}')\n",
    "        data = f.read()\n",
    "        data_str = data.decode(codec)\n",
    "        data_pd = pd.read_csv(StringIO(data_str))\n",
    "        \n",
    "        # pad missing zeros in microsecond field\n",
    "        data_pd['DateTime'] = data_pd.DateTime.str.pad(26, side='right', fillchar='0')\n",
    "        \n",
    "        # assign Datetime column as index\n",
    "        data_pd.set_index('DateTime', inplace=True)\n",
    "        \n",
    "        # sample start and end to determine date format\n",
    "        sample1 = data_pd.index[1]\n",
    "        sample2 = data_pd.index[-1]\n",
    "        \n",
    "        # determine datetime format and supply srftime directive\n",
    "        for row in data_pd:\n",
    "            if data_pd.index[3] == '/':\n",
    "                if sample1[0:2] == sample2[0:2]:\n",
    "                    data_pd.index = pd.to_datetime(data_pd.index, format=\"%m/%d/%Y %H:%M:%S.%f\")\n",
    "                elif sample1[3:5] == sample2[3:4]:\n",
    "                    data_pd.index = pd.to_datetime(data_pd.index, format=\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "            elif data_pd.index[5] == '/':\n",
    "                if sample1[9:11] == sample2[9:11]:\n",
    "                    data_pd.index = pd.to_datetime(data_pd.index, format=\"%Y/%d/%m %H:%M:%S.%f\")\n",
    "                elif sample[6:8] == sample2[6:8]:\n",
    "                    data_pd.index = pd.to_datetime(data_pd.index, format=\"%Y/%m/%d %H:%M:%S.%f\")\n",
    "        \n",
    "        print(\"\\nDATA SUMMARY:\")\n",
    "        print(data_pd.info())\n",
    "        \n",
    "        # Load data into database\n",
    "        store = pd.HDFStore(hdf5_file)\n",
    "        symbol = file[:6]\n",
    "        store.append(symbol, data_pd, format='t') \n",
    "        store.flush()\n",
    "        print(\"\\nH5 DATASTORE SUMMARY:\")\n",
    "        print(store.info()+\"\\n\"+\"-\"*75)\n",
    "        store.close()\n",
    "\n",
    "#---------------------\n",
    "# Create and play noise to notify script has completed\n",
    "# source = https://realpython.com/playing-and-recording-sound-python/#simpleaudio\n",
    "#---------------------\n",
    "frequency = 440  # Our played note will be 440 Hz\n",
    "fs = 44100  # 44100 samples per second\n",
    "seconds = 3  # Note duration of 3 seconds\n",
    "\n",
    "# Generate array with seconds*sample_rate steps, ranging between 0 and seconds\n",
    "t = np.linspace(0, seconds, seconds * fs, False)\n",
    "\n",
    "# Generate a 440 Hz sine wave\n",
    "note = np.sin(frequency * t * 2 * np.pi)\n",
    "\n",
    "# Ensure that highest value is in 16-bit range\n",
    "audio = note * (2**15 - 1) / np.max(np.abs(note))\n",
    "# Convert to 16-bit data\n",
    "audio = audio.astype(np.int16)\n",
    "\n",
    "# Start playback\n",
    "play_obj = sa.play_buffer(audio, 1, 2, fs)\n",
    "\n",
    "# Wait for playback to finish before exiting\n",
    "play_obj.wait_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_2020.11",
   "language": "python",
   "name": "anaconda_2020.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
