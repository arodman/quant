{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "#K:\\2020_2431\\FX valuation model 2020\\g10\n",
    "os.chdir('K:/2020_2431/FX valuation model 2020/g10/')\n",
    "\n",
    "df = pd.read_excel(r'K:\\2020_2431\\FX valuation model 2020\\g10\\Python FX Data v4.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read mapping\n",
    "map = pd.read_csv(r'K:\\2020_2431\\FX valuation model 2020\\g10\\Python FX Data Map v3.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set date index\n",
    "df['Dates'] = pd.to_datetime(df.Dates)\n",
    "df.set_index('Dates', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common data transformations\n",
    "df['brent'] = df['co1 comdty']\n",
    "df['10Y BTP spread'] = df['gtitl10y govt'] - df['gtdem10y govt']\n",
    "df['US 2s10s'] = df['ussa10 curncy'] - df['ussa2 curncy']\n",
    "\n",
    "#create 2Y swap series for each G10 pair\n",
    "for m in range(len(map)):\n",
    "    df['2Y spread ' + map['g10_pairs'][m]] = df[map['twoy_swap_1'][m]] - df[map['twoy_swap_2'][m]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regress full time horizon\n",
    "def regress(Y, X):\n",
    "\n",
    "    #clean the data\n",
    "    Y = Y.dropna()\n",
    "    X = X.dropna()\n",
    "    \n",
    "    #make Y matrix the same shape as X\n",
    "    YX = pd.concat([Y, X], axis=1).reindex(X.index).dropna()\n",
    "    Y = YX.iloc[:,0]\n",
    "    X = YX.drop(YX.columns[0], axis = 1)\n",
    "    \n",
    "    print(YX.corr())\n",
    "    \n",
    "    #fit the model with a constant\n",
    "    X1 = sm.add_constant(X)\n",
    "    reg = sm.OLS(Y, X1).fit()\n",
    "    print(reg.summary())\n",
    "\n",
    "    #calculate and plot residuals\n",
    "    predictions = reg.predict()\n",
    "    residuals = predictions - Y\n",
    "   \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.plot(residuals, color = 'blue')\n",
    "    \n",
    "    plt.title('Residuals', fontsize = 16)\n",
    "    \n",
    "    for year in range(Y.index[0].year, Y.index[-1].year+1):\n",
    "        plt.axvline(datetime(year,1,1), linestyle = '--', color = 'k', alpha = 0.5)\n",
    "    plt.show()\n",
    "    \n",
    "    #create exportable dataframe for actual data, predictions and residuals\n",
    "    predictions = pd.Series(predictions, name = 'Predictions', index = Y.index)\n",
    "    results = pd.DataFrame(predictions, index = Y.index)\n",
    "    results['Actual'] = Y\n",
    "    results['Residuals'] = results['Predictions'] - results['Actual']\n",
    "    \n",
    "    #plot actual data vs. predictions\n",
    "    predictions = pd.Series(predictions, index = Y.index)\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.plot(Y)\n",
    "    plt.plot(predictions)\n",
    "    plt.legend(('Actual', 'Model Fit'), fontsize = 20)\n",
    "    plt.title('Full Year Model Fit', fontsize = 20)\n",
    "    \n",
    "    for year in range(predictions.index[0].year, predictions.index[-1].year+1):\n",
    "        plt.axvline(datetime(year,1,1), linestyle = '--', color = 'k', alpha = 0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling regression (for 3m, 6m, 1y, 2y, 4y horizons) WIP\n",
    "def rolling_reg(Y, X, ccy_id, model_id):\n",
    "    \n",
    "    #clean data\n",
    "    Y = Y.dropna()\n",
    "    X = X.dropna()\n",
    "\n",
    "    #make Y matrix the same shape as X\n",
    "    YX = pd.concat([Y, X], axis=1).reindex(X.index).dropna()\n",
    "\n",
    "    #create list for timeframes where numbers are days in the window (3m = 63; 6m = 126; 1y = 252; 2y = 504; 4y = 1008)\n",
    "#     time_frame_id = ['3m', '6m', '1y', '2y', '4y', 'grow']\n",
    "#     time_frames = [63, 126, 252, 504, 1008, 63]\n",
    "\n",
    "    time_frame_id = ['2y']\n",
    "    time_frames = [504]\n",
    "    \n",
    "    #create dataframe for results\n",
    "    results = pd.DataFrame(index = Y.index)\n",
    "    \n",
    "    #loop for time frames\n",
    "    for tf in range(len(time_frames)):\n",
    "        time_frame = time_frame_id[tf]\n",
    "        m = time_frames[tf]\n",
    "\n",
    "        #create series for rolling predictions\n",
    "        Y_test = YX[YX.index[m]:]\n",
    "        Y_test = Y_test[Y_test.columns[0]]\n",
    "        rolling_predictions = np.zeros_like(Y_test)\n",
    "        rolling_predictions = pd.Series(index = Y_test.index)\n",
    "\n",
    "        #create series for rolling intercepts, betas, and r-squared\n",
    "        intercept = np.zeros_like(Y_test)\n",
    "        beta = pd.DataFrame()\n",
    "        for x in X.columns:\n",
    "            beta[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'beta_' + x] = np.zeros_like(Y_test)\n",
    "        beta = beta.reindex(Y_test.index)\n",
    "        r2 = np.zeros_like(Y_test)\n",
    "\n",
    "        #generate rolling predictions\n",
    "        for t in range(m, len(YX)):\n",
    "\n",
    "            #limit YX dataframe\n",
    "            YX_lim = YX[YX.index[t-m]:YX.index[t]]\n",
    "\n",
    "            #taking Y and X series for regression\n",
    "            Y_lim = YX_lim[YX_lim.columns[0]]\n",
    "            X_lim = YX_lim.drop(YX_lim.columns[0], axis=1)\n",
    "\n",
    "            #fit the model with a constant\n",
    "            X1 = sm.add_constant(X_lim)\n",
    "            reg = sm.OLS(Y_lim, X1).fit()\n",
    "\n",
    "            #taking predictions\n",
    "            fit = reg.predict()\n",
    "            fit = pd.Series(fit, name = 'Predictions', index = Y_lim.index)\n",
    "\n",
    "            #append rolling predictions\n",
    "            rolling_predictions[t-m] = fit[-1]\n",
    "\n",
    "            #append rolling intercepts\n",
    "            intercept[t-m] = reg.params[0]\n",
    "\n",
    "            #append rolling betas\n",
    "            for y in range(0, len(beta.columns)):\n",
    "                beta[beta.columns[y]][t-m] = reg.params[y+1]\n",
    "\n",
    "            #append rolling rsquared\n",
    "            r2[t-m] = reg.rsquared\n",
    "\n",
    "        #solve for errors\n",
    "        errors = rolling_predictions - Y_test\n",
    "        \n",
    "        #put important data into a dataframe for export\n",
    "        results[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'actual'] = Y_test\n",
    "        results = pd.concat([results, X], axis = 1).reindex(Y_test.index)\n",
    "        results[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'intercept'] = intercept\n",
    "        results = pd.concat([results, beta], axis = 1)\n",
    "        results[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'r2'] = r2\n",
    "        results[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'prediction'] = rolling_predictions\n",
    "        results[ccy_id + '_' + time_frame + '_' + model_id + '_' + 'error'] = errors\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full period regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#full period regressions for G10 pairs\n",
    "for r in range(len(map)):\n",
    "    ccy_pair = map['g10_pairs'][r]\n",
    "    Y = df[map['g10_pairs'][r] + ' curncy']\n",
    "    print(ccy_pair)\n",
    "    \n",
    "    #model combinations\n",
    "    X1 = df[['2Y spread ' +  map['g10_pairs'][r]]]\n",
    "    X2 = df[['10Y BTP spread']]\n",
    "    X3 = df[['US 2s10s']]\n",
    "    X4 = df[['brent']]\n",
    "    X5 = df[['2Y spread ' +  map['g10_pairs'][r],'10Y BTP spread' ]]\n",
    "    X6 = df[['2Y spread ' +  map['g10_pairs'][r],'US 2s10s' ]]\n",
    "    X7 = df[['2Y spread ' +  map['g10_pairs'][r],'brent' ]]\n",
    "    X8 = df[['10Y BTP spread','US 2s10s' ]]\n",
    "    X9 = df[['10Y BTP spread','brent' ]]\n",
    "    X10 = df[['US 2s10s', 'brent']]\n",
    "    X11 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s']]\n",
    "    X12 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'brent']]\n",
    "    X13 = df[['2Y spread ' +  map['g10_pairs'][r], 'US 2s10s', 'brent']]\n",
    "    X14 = df[['10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "    X15 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "\n",
    "    #make a list of models\n",
    "    X_list = [X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15]\n",
    "    \n",
    "    #regress the models\n",
    "    for x in range(len(X_list)):\n",
    "        regress(Y, X_list[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling regressions for G10 pairs (first half)\n",
    "\n",
    "#create output dataframe\n",
    "output = pd.DataFrame()\n",
    "\n",
    "#loops for G10 pairs\n",
    "for r in range(round(len(map)/2)):\n",
    "    ccy_pair = map['g10_pairs'][r]\n",
    "    Y = df[map['g10_pairs'][r] + ' curncy']\n",
    "    \n",
    "    #model combinations\n",
    "    X1 = df[['2Y spread ' +  map['g10_pairs'][r]]]\n",
    "    X2 = df[['10Y BTP spread']]\n",
    "    X3 = df[['US 2s10s']]\n",
    "    X4 = df[['brent']]\n",
    "    X5 = df[['2Y spread ' +  map['g10_pairs'][r],'10Y BTP spread' ]]\n",
    "    X6 = df[['2Y spread ' +  map['g10_pairs'][r],'US 2s10s' ]]\n",
    "    X7 = df[['2Y spread ' +  map['g10_pairs'][r],'brent' ]]\n",
    "    X8 = df[['10Y BTP spread','US 2s10s' ]]\n",
    "    X9 = df[['10Y BTP spread','brent' ]]\n",
    "    X10 = df[['US 2s10s', 'brent']]\n",
    "    X11 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s']]\n",
    "    X12 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'brent']]\n",
    "    X13 = df[['2Y spread ' +  map['g10_pairs'][r], 'US 2s10s', 'brent']]\n",
    "    X14 = df[['10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "    X15 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "\n",
    "    #make a list of models\n",
    "    X_list = [X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15]\n",
    "    \n",
    "    #loops for models\n",
    "    for x in range(len(X_list)):\n",
    "        output = pd.concat([output, rolling_reg(Y, X_list[x], ccy_pair, 'X' + str(x+1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rolling regressions for G10 pairs (second half)\n",
    "\n",
    "\n",
    "#loops for G10 pairs\n",
    "for r in range(round(len(map)/2), len(map)):\n",
    "    ccy_pair = map['g10_pairs'][r]\n",
    "    Y = df[map['g10_pairs'][r] + ' curncy']\n",
    "    \n",
    "    #model combinations\n",
    "    X1 = df[['2Y spread ' +  map['g10_pairs'][r]]]\n",
    "    X2 = df[['10Y BTP spread']]\n",
    "    X3 = df[['US 2s10s']]\n",
    "    X4 = df[['brent']]\n",
    "    X5 = df[['2Y spread ' +  map['g10_pairs'][r],'10Y BTP spread' ]]\n",
    "    X6 = df[['2Y spread ' +  map['g10_pairs'][r],'US 2s10s' ]]\n",
    "    X7 = df[['2Y spread ' +  map['g10_pairs'][r],'brent' ]]\n",
    "    X8 = df[['10Y BTP spread','US 2s10s' ]]\n",
    "    X9 = df[['10Y BTP spread','brent' ]]\n",
    "    X10 = df[['US 2s10s', 'brent']]\n",
    "    X11 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s']]\n",
    "    X12 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'brent']]\n",
    "    X13 = df[['2Y spread ' +  map['g10_pairs'][r], 'US 2s10s', 'brent']]\n",
    "    X14 = df[['10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "    X15 = df[['2Y spread ' +  map['g10_pairs'][r], '10Y BTP spread', 'US 2s10s', 'brent']]\n",
    "\n",
    "    #make a list of models\n",
    "    X_list = [X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15]\n",
    "    \n",
    "    #loops for models\n",
    "    for x in range(len(X_list)):\n",
    "        output = pd.concat([output, rolling_reg(Y, X_list[x], ccy_pair, 'X' + str(x+1))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot rolling model fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#inputs\n",
    "ccy_pair = 'usdeur'\n",
    "time_frame = '2y'   #choices are: 3m, 6m, 1y, 2y, 4y, grow\n",
    "\n",
    "#plot models\n",
    "for x in range(len(X_list)):\n",
    "    plt.figure(figsize = (20,7))\n",
    "    plt.plot(output[ccy_pair + '_' + time_frame + '_X1_actual'], color = 'red')\n",
    "    plt.plot(output[ccy_pair + '_' + time_frame + '_X' + str(x+1) + '_prediction'], color = 'blue')\n",
    "    plt.legend(('Actual', 'Model Fit'), fontsize = 10)\n",
    "    plt.title('Model ' + str(x+1), fontsize = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alan Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cut the pairs in  2 GROUPS\n",
    "## ADD THE DIFFERENT TRIME HROOIZON\n",
    "## add title to each graph and labels and \n",
    "### lets add the f statiscs asn an additional column\n",
    "### accumualated residuals rolling\n",
    "### save the last charts ### create JPG\n",
    "#SAVE AS PDF MERGED\n",
    "## add timeclocks\n",
    "###only process marginal deltan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### multuipole loops\n",
    "\n",
    "n=0\n",
    "for w in range(len(time_ref_list)): \n",
    "    print(\"time loop\")\n",
    "    print(\"w \"+str(w))\n",
    "    time_ref_start_name=str(time_ref_start[w]) \n",
    "    time_ref_end_name=str(time_ref_end[w]) \n",
    "    time_ref_name=str(time_ref_start_name)+\" / \"+str(time_ref_end_name)\n",
    "\n",
    "    #####filter time set here\n",
    "    for x in range(len(x0_list)): \n",
    "        print(\"x loop\")\n",
    "        print(\"x \"+str(x))\n",
    "        x_variable=str(x0_list[x])\n",
    "        print(x_variable)\n",
    "        ###fitlere variable here\n",
    "        for y in range(len(y0_list)): \n",
    "            ###fitlere variable here\n",
    "            print(\"y loop\")\n",
    "            print(\"y \"+str(y))\n",
    "            y_variable=str(y0_list[y])\n",
    "            print(y_variable)\n",
    "         \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add tittle\n",
    "### speciifc the variables of the medeil in the title or subtittle.\n",
    "\n",
    "\n",
    "fig.suptitle(\"EM Global Macro Sensitivity Analysis: \"+str(x_variable)+\" vs. \"+str(y_variable)+\" Time: (\"+str(time_ref_name)+\")\",size = 15)\n",
    "            plt.title('Interpretation: t-stat ->  significance // reg coefficient -> sensitivity ', size=parameter_l)\n",
    "            plt.ylabel(y_label, size=parameter_l)\n",
    "            plt.xlabel(x_label, size=parameter_l)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save as jpgs\n",
    "\n",
    "\n",
    "\n",
    "        plt.savefig(str(y_var)+\"/table_\"+str(y_var)+\"th_\"+str(th)+\".jpg\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        plt.close('all')\n",
    "        plt.clf()\n",
    "        plt.cla()\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###merge all pdfs to one fielm \n",
    "\n",
    "source_dir= 'K://table/'\n",
    "source_dir2= 'K://Summary/'\n",
    " \n",
    "\n",
    "g0_list=['dv_cds5y_','dv_fx_','dv_l_msci_','dv_lccy_','dv_hccy_']  \n",
    "#g0_list=['dv_cds5y_','dv_fx_','dv_l_msci_']\n",
    "#y0_list=['dv_cds5y_','dv_fx_','dv_l_msci_','dv_lccy_','dv_hccy_']\n",
    "\n",
    "#####filter time set here\n",
    "for x in range(len(g0_list)): \n",
    "        merger = PdfFileMerger()\n",
    "        variable=str(g0_list[x])\n",
    "        variable_folder = str(variable)+'/'\n",
    "        source_dir1 = str(source_dir) + str(variable_folder) +\"/\"\n",
    "        print(variable)\n",
    "        print(source_dir1)\n",
    "        for item in os.listdir(source_dir1):\n",
    "             if item.endswith('pdf'):\n",
    "                merger.append(source_dir1 + item)\n",
    "\n",
    "        merger.write(source_dir2+variable+\"_Complete.pdf\") \n",
    "        #merger.write(public_location+variable+\"_Complete.pdf\")       \n",
    "        merger.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "print(table_pv)\n",
    "print(\"Cmplete\")\n",
    "now = datetime.now()\n",
    "print(\"Y\",now.year,\"/ M\", now.month,\"/ D\", now.day, \"/// H\",now.hour,\": M\", now.minute,\": S\", now.second)\n",
    "#timer: 101.14274072647095 seconds++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### acumualrte the residual\n",
    "\n",
    "list_loop=list_x1\n",
    "for t in range(len(time)):\n",
    "    t1=str(time[t])\n",
    "    print(t1)\n",
    "    for x in range(len(list_loop)):\n",
    "        print(t1)\n",
    "        print(x)\n",
    "        y=str(list_loop[x])      \n",
    "        f=str(\"factor_reg_\"+str(y)) \n",
    "        print(f)\n",
    "        df[str('acumm_factor_'+str(t1))]= df[str(f)].rolling(window=rolling_window2).agg(lambda x : x.prod())\n",
    "        df.rename(columns={str('acumm_factor_'+str(t1)):(str('acumm_factor_'+str(t1))+\"_\"+str(y))}, inplace=True)\n",
    "        ff = f[-6:]\n",
    "        ff1=(\"lg\"+str(t1)+\"_\"+str(ff))\n",
    "        print(ff)\n",
    "        print(ff1)   \n",
    "        df[\"output\"]=(df[\"acumm_factor_\"+str(t1)+\"_\"+str(y)])+0\n",
    "        df[\"output0\"]=(df[str(ff1)])\n",
    "        df[\"output\"]=df[\"output\"]*df[\"output0\"]\n",
    "        del df[\"output0\"]\n",
    "        df.rename(columns={\"output\":(\"output_\"+str(t1)+\"_\"+str(y))}, inplace=True)   \n",
    "        df[\"acumm_res\"]=((df[(\"output_\"+str(t1)+\"_\"+str(y))]/df[str(ff)])-1)\n",
    "        df.rename(columns={'acumm_res':(\"acumm_res_\"+str(t1)+\"_\"+str(y))}, inplace=True)    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Anaconda_2020.11",
   "language": "python",
   "name": "anaconda_2020.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
